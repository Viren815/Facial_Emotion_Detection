{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RM-DenseNet-169.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "OEJR6rqkeITU"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAEjny-zrrBh"
      },
      "source": [
        "##Mounting Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEK0NIjVXujV",
        "outputId": "e36dc731-85dc-48d0-fcf3-77494a8606e1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KDiSM8qtalh"
      },
      "source": [
        "##Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkYTIM6qnmwo"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import keras\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "from keras.layers import Conv2D, Flatten, MaxPooling2D,Dense,Dropout,SpatialDropout2D\n",
        "from keras.models  import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img, array_to_img\n",
        "import random,os,glob\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import SGD\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Activation,Dense,Flatten,Dropout,MaxPooling2D,GlobalAveragePooling2D,BatchNormalization\n",
        "import shutil as sh\n",
        "import os\n",
        "from keras.applications.xception import Xception\n",
        "from PIL import Image\n",
        "from keras.preprocessing import image\n",
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2Qg4Rcmc5oL"
      },
      "source": [
        "##Importing dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "S7UiuRWpobtF",
        "outputId": "e31a9caa-2b72-4589-cb01-7d1cb194cdb9"
      },
      "source": [
        "filname = '/content/drive/MyDrive/Research Methodology/fer2013.csv'\n",
        "names=['emotion','pixels','usage']\n",
        "df=pd.read_csv('/content/drive/MyDrive/Research Methodology/fer2013.csv',names=names, na_filter=False)\n",
        "im=df['pixels']\n",
        "df.head(10)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>pixels</th>\n",
              "      <th>usage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>emotion</td>\n",
              "      <td>pixels</td>\n",
              "      <td>Usage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2</td>\n",
              "      <td>55 55 55 55 55 54 60 68 54 85 151 163 170 179 ...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>4</td>\n",
              "      <td>20 17 19 21 25 38 42 42 46 54 56 62 63 66 82 1...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3</td>\n",
              "      <td>77 78 79 79 78 75 60 55 47 48 58 73 77 79 57 5...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3</td>\n",
              "      <td>85 84 90 121 101 102 133 153 153 169 177 189 1...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   emotion                                             pixels     usage\n",
              "0  emotion                                             pixels     Usage\n",
              "1        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
              "2        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
              "3        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
              "4        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
              "5        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training\n",
              "6        2  55 55 55 55 55 54 60 68 54 85 151 163 170 179 ...  Training\n",
              "7        4  20 17 19 21 25 38 42 42 46 54 56 62 63 66 82 1...  Training\n",
              "8        3  77 78 79 79 78 75 60 55 47 48 58 73 77 79 57 5...  Training\n",
              "9        3  85 84 90 121 101 102 133 153 153 169 177 189 1...  Training"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGg29lj4c-RX"
      },
      "source": [
        "##Dividing Data into X and Y "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uLBc8Icoejm"
      },
      "source": [
        "def train_test(filname):\n",
        "    Y = []\n",
        "    X = []\n",
        "    data = True\n",
        "    for row in open(filname):\n",
        "        if data:\n",
        "            data = False\n",
        "        else:\n",
        "            train = row.split(',')\n",
        "            Y.append(int(train[0]))\n",
        "            X.append([int(p) for p in train[1].split()])\n",
        "\n",
        "    X = np.array(X) / 255.0 \n",
        "    Y = np.array(Y)\n",
        "    return X, Y\n",
        "    "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWOIVbGfohcA",
        "outputId": "5666b260-00b0-444a-b4b5-aeda5f457789"
      },
      "source": [
        "X, Y = train_test(filname)\n",
        "num_class = len(set(Y))\n",
        "print(num_class)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEJR6rqkeITU"
      },
      "source": [
        "##Dividing Data into Train and Test "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhFPB9ULwVHs"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gl20E-syeUF9"
      },
      "source": [
        "##Preprocessing Steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfa2j3WsHJOp"
      },
      "source": [
        "X_train = X_train.astype('float32') / 255.\n",
        "X_test = X_test.astype('float32') / 255.\n",
        "X_train = np.reshape(X_train, (len(X_train), 48, 48, 1))\n",
        "X_test = np.reshape(X_test, (len(X_test), 48, 48, 1))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzNkgCtHVgT9",
        "outputId": "8cead5fa-bceb-4385-f588-bbd9ef23d1d8"
      },
      "source": [
        "train_images = tf.image.grayscale_to_rgb(\n",
        "    (tf.convert_to_tensor(X_train, name=None))\n",
        "    # name=None\n",
        ")\n",
        "# train_images = train_images / 255\n",
        "print(train_images.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28709, 48, 48, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYpHDtJUJ-nw"
      },
      "source": [
        "train_images = tf.image.resize(train_images, [128,128])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjlPPC5CKRQk",
        "outputId": "080666df-486c-40f2-9387-6dded88c5fef"
      },
      "source": [
        "test_images = tf.image.grayscale_to_rgb(\n",
        "    (tf.convert_to_tensor(X_test, name=None))\n",
        "    # name=None\n",
        ")\n",
        "print(test_images.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7178, 48, 48, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riZVBjIiKedm"
      },
      "source": [
        "test_images = tf.image.resize(test_images, [128,128])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrD_VPWOVpbk"
      },
      "source": [
        "y_train = (np.arange(num_class) == y_train[:, None]).astype(np.float32)\n",
        "y_test = (np.arange(num_class) == y_test[:, None]).astype(np.float32)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUdjRF4Vffgp"
      },
      "source": [
        "##Loading the Pretrained Model ResNet-152 with Transfer learning ImageNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiTZWjQLzBkY",
        "outputId": "6791241e-4de4-4579-dcd2-d1fae2b3e9cb"
      },
      "source": [
        "model = Sequential()\n",
        "resnet152model = tf.keras.applications.DenseNet169(include_top=False, weights='imagenet', input_shape=(128, 128, 3))\n",
        "model.add(resnet152model)\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512,activation='relu'))\n",
        "model.add(Dense(512,activation='relu'))\n",
        "model.add(Dense(7,activation='softmax'))\n",
        "adam = SGD(learning_rate=0.001, decay=1e-5, momentum=0.8, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=adam,\n",
        "              metrics=['acc']) \n",
        "\n",
        "# data_train.fit(X_train)\n",
        "history = model.fit(train_images,y_train, batch_size=32,epochs=10, validation_data=(test_images,y_test))\n",
        "score= model.evaluate(test_images, y_test, batch_size=32,verbose=3)\n",
        "print(\"test accuracy\", score[1])  "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "898/898 [==============================] - 230s 183ms/step - loss: 1.5471 - acc: 0.4059 - val_loss: 1.5044 - val_acc: 0.4284\n",
            "Epoch 2/10\n",
            "898/898 [==============================] - 160s 178ms/step - loss: 0.9842 - acc: 0.6297 - val_loss: 1.2132 - val_acc: 0.5411\n",
            "Epoch 3/10\n",
            "898/898 [==============================] - 170s 189ms/step - loss: 0.7889 - acc: 0.7068 - val_loss: 1.0203 - val_acc: 0.6317\n",
            "Epoch 4/10\n",
            "898/898 [==============================] - 170s 189ms/step - loss: 0.5826 - acc: 0.7845 - val_loss: 1.0797 - val_acc: 0.6326\n",
            "Epoch 5/10\n",
            "898/898 [==============================] - 170s 189ms/step - loss: 0.4183 - acc: 0.8505 - val_loss: 1.1620 - val_acc: 0.6369\n",
            "Epoch 6/10\n",
            "898/898 [==============================] - 170s 189ms/step - loss: 0.3108 - acc: 0.8920 - val_loss: 1.1686 - val_acc: 0.6421\n",
            "Epoch 7/10\n",
            "898/898 [==============================] - 160s 178ms/step - loss: 0.2290 - acc: 0.9215 - val_loss: 1.3221 - val_acc: 0.6482\n",
            "Epoch 8/10\n",
            "898/898 [==============================] - 169s 188ms/step - loss: 0.1710 - acc: 0.9407 - val_loss: 1.4766 - val_acc: 0.6360\n",
            "Epoch 9/10\n",
            "898/898 [==============================] - 160s 178ms/step - loss: 0.1441 - acc: 0.9530 - val_loss: 1.4939 - val_acc: 0.6436\n",
            "Epoch 10/10\n",
            "898/898 [==============================] - 169s 189ms/step - loss: 0.1446 - acc: 0.9501 - val_loss: 1.5391 - val_acc: 0.6583\n",
            "test accuracy 0.6582613587379456\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "JJ8YLahADJFH",
        "outputId": "8253f199-2dad-4987-e9a6-b0166881eb7a"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "results = model.predict_classes(test_images)\n",
        "cm = confusion_matrix(np.where(y_test == 1)[1], results)\n",
        "plt.figure(figsize=(30, 30))\n",
        "plt.matshow(cm)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.colorbar()\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2160x2160 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaHdufmnaEkX"
      },
      "source": [
        "##References\n",
        "1) S. (2019, November 27). Facial Expression Detection (CNN). Kaggle. https://www.kaggle.com/shawon10/facial-expression-detection-cnn\n",
        "\n",
        "2) J. (2019a, January 3). Face expression recognition with Deep Learning. Kaggle. https://www.kaggle.com/jonathanoheix face-expression-recognition-with-deep-learning\n",
        "\n",
        "3) G. (2020, April 18). Facial Emotion Recognition. Kaggle. https://www.kaggle.com/gauravsharma99/facial-emotion-recognition\n",
        "\n",
        "4) https://gist.github.com/Nabeel110/01210a28cbd8b53c13b42330abc253ad"
      ]
    }
  ]
}