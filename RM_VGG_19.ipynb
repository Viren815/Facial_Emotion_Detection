{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RM-VGG-19.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAEjny-zrrBh"
      },
      "source": [
        "##Mounting Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEK0NIjVXujV",
        "outputId": "bbe73aea-ee0f-4192-ae8b-5195497f19cb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KDiSM8qtalh"
      },
      "source": [
        "##Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkYTIM6qnmwo"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import keras\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "from keras.layers import Conv2D, Flatten, MaxPooling2D,Dense,Dropout,SpatialDropout2D\n",
        "from keras.models  import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img, array_to_img\n",
        "import random,os,glob\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import SGD\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Activation,Dense,Flatten,Dropout,MaxPooling2D,GlobalAveragePooling2D,BatchNormalization\n",
        "import shutil as sh\n",
        "import os\n",
        "from keras.applications.xception import Xception\n",
        "from PIL import Image\n",
        "from keras.preprocessing import image\n",
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2Qg4Rcmc5oL"
      },
      "source": [
        "##Importing dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "S7UiuRWpobtF",
        "outputId": "a2a03fd1-e166-4a8c-a860-a784f66eb63f"
      },
      "source": [
        "filname = '/content/drive/MyDrive/Research Methodology/fer2013.csv'\n",
        "names=['emotion','pixels','usage']\n",
        "df=pd.read_csv('/content/drive/MyDrive/Research Methodology/fer2013.csv',names=names, na_filter=False)\n",
        "im=df['pixels']\n",
        "df.head(10)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>pixels</th>\n",
              "      <th>usage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>emotion</td>\n",
              "      <td>pixels</td>\n",
              "      <td>Usage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2</td>\n",
              "      <td>55 55 55 55 55 54 60 68 54 85 151 163 170 179 ...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>4</td>\n",
              "      <td>20 17 19 21 25 38 42 42 46 54 56 62 63 66 82 1...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3</td>\n",
              "      <td>77 78 79 79 78 75 60 55 47 48 58 73 77 79 57 5...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3</td>\n",
              "      <td>85 84 90 121 101 102 133 153 153 169 177 189 1...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   emotion                                             pixels     usage\n",
              "0  emotion                                             pixels     Usage\n",
              "1        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
              "2        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
              "3        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
              "4        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
              "5        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training\n",
              "6        2  55 55 55 55 55 54 60 68 54 85 151 163 170 179 ...  Training\n",
              "7        4  20 17 19 21 25 38 42 42 46 54 56 62 63 66 82 1...  Training\n",
              "8        3  77 78 79 79 78 75 60 55 47 48 58 73 77 79 57 5...  Training\n",
              "9        3  85 84 90 121 101 102 133 153 153 169 177 189 1...  Training"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGg29lj4c-RX"
      },
      "source": [
        "##Dividing Data into X and Y "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uLBc8Icoejm"
      },
      "source": [
        "def train_test(filname):\n",
        "    Y = []\n",
        "    X = []\n",
        "    data = True\n",
        "    for row in open(filname):\n",
        "        if data:\n",
        "            data = False\n",
        "        else:\n",
        "            train = row.split(',')\n",
        "            Y.append(int(train[0]))\n",
        "            X.append([int(p) for p in train[1].split()])\n",
        "\n",
        "    X = np.array(X) / 255.0 \n",
        "    Y = np.array(Y)\n",
        "    return X, Y\n",
        "    "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWOIVbGfohcA",
        "outputId": "978b1c71-99c5-44ef-e4e5-6d146485ceba"
      },
      "source": [
        "X, Y = train_test(filname)\n",
        "num_class = len(set(Y))\n",
        "print(num_class)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEJR6rqkeITU"
      },
      "source": [
        "##Dividing Data into Train and Test "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhFPB9ULwVHs"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gl20E-syeUF9"
      },
      "source": [
        "##Preprocessing Steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfa2j3WsHJOp"
      },
      "source": [
        "X_train = X_train.astype('float32') / 255.\n",
        "X_test = X_test.astype('float32') / 255.\n",
        "X_train = np.reshape(X_train, (len(X_train), 48, 48, 1))\n",
        "X_test = np.reshape(X_test, (len(X_test), 48, 48, 1))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzNkgCtHVgT9",
        "outputId": "ea94dbc2-9abc-4583-a828-9d84cd466007"
      },
      "source": [
        "train_images = tf.image.grayscale_to_rgb(\n",
        "    (tf.convert_to_tensor(X_train, name=None))\n",
        "    # name=None\n",
        ")\n",
        "# train_images = train_images / 255\n",
        "print(train_images.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28709, 48, 48, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYpHDtJUJ-nw"
      },
      "source": [
        "train_images = tf.image.resize(train_images, [128,128])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjlPPC5CKRQk",
        "outputId": "f2f6ddd0-d5e9-4bc2-f74e-b0a7ddc4438f"
      },
      "source": [
        "test_images = tf.image.grayscale_to_rgb(\n",
        "    (tf.convert_to_tensor(X_test, name=None))\n",
        "    # name=None\n",
        ")\n",
        "print(test_images.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7178, 48, 48, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riZVBjIiKedm"
      },
      "source": [
        "test_images = tf.image.resize(test_images, [128,128])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrD_VPWOVpbk"
      },
      "source": [
        "y_train = (np.arange(num_class) == y_train[:, None]).astype(np.float32)\n",
        "y_test = (np.arange(num_class) == y_test[:, None]).astype(np.float32)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUdjRF4Vffgp"
      },
      "source": [
        "##Loading the Pretrained Model Vgg-19 with Transfer learning ImageNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiTZWjQLzBkY",
        "outputId": "d930b922-1ef3-43a8-9afb-9ebf4a69e4ba"
      },
      "source": [
        "model = Sequential()\n",
        "vgg19model = tf.keras.applications.VGG19(include_top=False, weights='imagenet', input_shape=(128, 128, 3))\n",
        "model.add(vgg19model)\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512,activation='relu'))\n",
        "model.add(Dense(512,activation='relu'))\n",
        "model.add(Dense(7,activation='softmax'))\n",
        "adam = SGD(learning_rate=0.001, decay=1e-5, momentum=0.8, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=adam,\n",
        "              metrics=['acc']) \n",
        "\n",
        "# data_train.fit(X_train)\n",
        "history = model.fit(train_images,y_train, batch_size=32,epochs=10, validation_data=(test_images,y_test))\n",
        "score= model.evaluate(test_images, y_test, batch_size=32,verbose=3)\n",
        "print(\"test accuracy\", score[1])  "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 1s 0us/step\n",
            "Epoch 1/10\n",
            "898/898 [==============================] - 220s 185ms/step - loss: 1.8341 - acc: 0.2375 - val_loss: 1.8096 - val_acc: 0.2559\n",
            "Epoch 2/10\n",
            "898/898 [==============================] - 162s 180ms/step - loss: 1.8136 - acc: 0.2522 - val_loss: 1.8065 - val_acc: 0.2559\n",
            "Epoch 3/10\n",
            "898/898 [==============================] - 162s 181ms/step - loss: 1.8174 - acc: 0.2473 - val_loss: 1.8063 - val_acc: 0.2559\n",
            "Epoch 4/10\n",
            "898/898 [==============================] - 162s 181ms/step - loss: 1.8171 - acc: 0.2474 - val_loss: 1.8107 - val_acc: 0.2559\n",
            "Epoch 5/10\n",
            "898/898 [==============================] - 162s 181ms/step - loss: 1.8154 - acc: 0.2510 - val_loss: 1.8085 - val_acc: 0.2559\n",
            "Epoch 6/10\n",
            "898/898 [==============================] - 162s 180ms/step - loss: 1.8173 - acc: 0.2438 - val_loss: 1.8099 - val_acc: 0.2559\n",
            "Epoch 7/10\n",
            "898/898 [==============================] - 162s 181ms/step - loss: 1.8144 - acc: 0.2518 - val_loss: 1.8081 - val_acc: 0.2559\n",
            "Epoch 8/10\n",
            "898/898 [==============================] - 162s 181ms/step - loss: 1.8168 - acc: 0.2475 - val_loss: 1.8078 - val_acc: 0.2559\n",
            "Epoch 9/10\n",
            "898/898 [==============================] - 162s 181ms/step - loss: 1.8086 - acc: 0.2530 - val_loss: 1.8099 - val_acc: 0.2559\n",
            "Epoch 10/10\n",
            "898/898 [==============================] - 162s 181ms/step - loss: 1.8117 - acc: 0.2494 - val_loss: 1.8066 - val_acc: 0.2559\n",
            "test accuracy 0.2559208571910858\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "JJ8YLahADJFH",
        "outputId": "c59a7072-4bdb-4526-d1e0-d9449ea71595"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "results = model.predict_classes(test_images)\n",
        "cm = confusion_matrix(np.where(y_test == 1)[1], results)\n",
        "plt.figure(figsize=(30, 30))\n",
        "plt.matshow(cm)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.colorbar()\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2160x2160 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAARMAAAD2CAYAAAD1V2M9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAfVElEQVR4nO3debRcVZ328e9DgAAyG6SBEBM1YGMaA0ZAEURmkBa0HUBFsLHRFmhtdNli+wqiuFrb+VXxDYOAIIggGgGBgCCiDBkMCAQkDEpCJEzKaEhunvePvQsOl3vrnnvrnFu3qn6ftc5K1a5TZ59KUr/a85ZtQgihVau1+wZCCN0hgkkIoRIRTEIIlYhgEkKoRASTEEIlIpiEECoRwWQMkLS2pF9I+pukn7RwnfdJuqLKe2sHSb+UdFi77yMMTwSTYZD0XklzJT0paWn+T/+mCi79TmBT4KW23zXSi9g+x/beFdzPC0jaTZIlXdQv/bU5/ZqS1zlB0tlDnWd7P9tnjvB2Q5tEMClJ0rHAN4Evkb74k4DvAQdWcPmXA3+0vbKCa9XlIeANkl5aSDsM+GNVGSiJ/5OdynYcQxzABsCTwLuanDOeFGweyMc3gfH5td2AxcAngGXAUuCD+bXPA88CK3IeRwAnAGcXrj0ZMLB6fn44cA/wBHAv8L5C+nWF970RmAP8Lf/5xsJr1wBfAH6br3MFMGGQz9a4/+8DR+W0ccAS4HPANYVzvwXcDzwOzAN2yen79vucNxfu46R8H88Ar8ppH8qvnwxcWLj+l4GrALX7/0UVx967rePXbTu+1AFc1u77bXasPkSsCckbgLWAi5qc89/ATsB00hf/58Bngf+TX/8HUlDaAtgLuEDSz2wfL8nAq2y/H1J1YLBMJL0E+Dbwett3StoM2HiA8zYGLgH+AzgXeBdwiaRX2X4kn/ZeYD/Sl/+XwCeBTzf5jGcB3wC+C+wD3EoKnEVzgBNJAexjwE8kTbZ9maQvFT9nwaH5Pu4E1O+1TwALJB0O3E0KttOdI0une/jRPm68fGKpc9fY7O4JNd9OS6JIWc5LgYfdvBryPuBE28tsP0QqcRxaeH1Ffn2F7UtJv85bj/B+VgHTJK1te6nt2wY4563AXbZ/aHul7XOBO4B/LpzzA9t/tP0McD4pEA7K9u+AjSVtDXyAFFz6n3O27Udynl8jldiG+pxn2L4tv2dFv+s9Tfp7/DpwNnCM7cVDXK+DmD6vKnWMdRFMynkEmCCpWUluc+BPhed/ymnPXaNfMHoaWHe4N2L7KeA9wEeApZIukfTqEvfTuKctCs//MoL7+SFwNPAWBiipSfqkpIW5Z+qvpNLYUL+o9zd70faNpGqdSEGvaxhYhUsdY10Ek3KuB5YDBzU55wFSQ2rDJF5cBSjrKWCdwvN/KL5o+3LbewGbkUobp5S4n8Y9LRnhPTX8EPgocGkuNTxH0i7Ap4B3AxvZ3pBU3WlUXQb7RjT9pkg6ilTCeSBfv2sYs8J9pY6xrmPbTCTtS2rsGwecavt/asjjdOAAUqPp54DvSlpJaqxcAewJvMX2p0jtEp+VNIf05fgcqVg+VB5bknpFNpJ0GzATWAD8l6RJpC/jcYXzNyW1zVxJarB8klTt6e9S4P9Kei+p/eZmYAqpmjJlmH8Vz7F9r6Q3k0oK/a0HrCSV5OZLWhtYv/D6g8Beklazy5XbJW0FfJHUCPw0cJOkY3IefcBK2zNG+nmGyHtD4FRgGunf9F9tX191Pp1Q6iijI0smksaRGgH3A7YBDpG0TQ1ZnUHqhSDX/48lNao+RCqaHw38LJ/7RWAucAvwB2B+ThtKIzhdTAoSR5FKDz/O15qXX2tYLd/HA8CjwJuBf+9/0dzIegCpAfMBUo/Nm4F/yp9p/f7vKcv2dbYHKnVdDlxGCjRbk4JcsQrTGJD3iKT5Q+WTq5VnA1+2fbPtu4DPkKpN+9ieXlcgyb5F6kF5NfBaYGHVGRjow6WOMiSdLmmZpFsLaT+WtCAf90lakNMnS3qm8Nr3C+95naQ/SFok6duS+jeMD/BhxkCX0nAPUu/K5YXnxwHH1ZTXZODWUfxsPwf2qvH665AC3Y41XX8iqet2d+DimvK4j0G6sSvMYwNSt3utXdCv3XYNL1uyeakDmFvivncFth/s/yzwNeBz+fGg/7eBm0g/biL19O03VN4dWTIhNSIWf/EW88KGxY4kaTKwHXBjDdcel3+RlgGznRo16/BNUrtGnd0PBq6QNE/SkTXlMYVUAv2BpN9LOjV3y1fKQJ9d6ih1PftaUon1RXLp4t2kKvmg8nCD9W3f4BRZzqJ5eyHQodWcbiRpXeBC4OO2H6/6+rb7bE8nlRx2kDSt6jwkHQAssz2v6mv38ybb25OquUdJ2rWGPFYn/cKfbHs7UqN4szE4I7aq5FGBXYAHnaqLDVNysPx1bkCH9MNc7H4v9WPdqcFkCbBl4flEWu+laBtJa5ACyTm2f1pnXrb/ClxNbguq2M7A2yTdB5wH7F5mLs5w2V6S/1xG6p7eoeo8SF+gxYUS3AWk4FIpl2wvyW0mE/LcsMYx3FLZIbywVLIUmJSD5bHAjySNuC2tU4PJHGCqpCmS1gQOBma1+Z5GJBc9TwMW2v56TXlsknsmyD0se5G6lCtl+zjbE21PJv2b/MovHu3aEkkvkbRe4zGwN2kkbqVs/wW4Pw/QA9gDuL36fGBFyYM0cHJG4ZhZNp/cmP0OUsN+ztvLnUdD59Lk3cBWpB/m4rDcUj/WHRlMnAZ/HU3qPVgInO+BR4G2RNK5pDEmW0taLOmIqvMg/ZofSvoVb7Sq719xHpsBV0u6hRSIZ9u+eIj3jFWbAtdJupnUSHiJ7ctqyusY4Jz89zadNMmzYqKv5NGiPYE7XBg9nH9kxuXHrwCmAvfYXgo8Lmmn/GP3AVLHQPNP4pINOyGE6k3bdk1feEm5KTevnrR0nofoCs8/gLuRus8fBI63fZqkM4AbbBe7f/+FNI9qBalZ5njbv8ivzSANjVib1JtzjIcIFh07aC2EblFBqeM5tg8ZJP3wAdIuJLXVDXT+XNJgvdIimITQRmnQWnXBpJ0imITQZqscwSSE0KIomYQQKmHECo9r921UoiO7hhtqHEo96vnEZxmb+dSdR6NkMgpdw7Xr6GACjMp/2lHKJz7L2Myn5jxEn1crdYx1Uc0JoY3SSmtjP1CUMaaCyZoa77UoPzFzLdZhfW1c+6i70chnpHksnzS8iazjNt6Q8S/fclj5jP/zU8PKo9f/Xf7OUzzr5aXrJZ1QhSljTAWTtXgJO2qPdt9GR7nrv3asPY+pR9e1WkF3utFXlT7XVkdUYcoYU8EkhF60KkomIYRWGfGsu+Nr2B2fIoQOFQ2wIYTK9MVw+hBCq4zoi5JJCKEKq6I3J4TQqjScvjuCSa2fQtK+ku7MG/nUsrJ3CJ2sMdGvzDHW1VYyKey6txdppe85kmbZrnxR3hA6lU3XDFqr81PsACyyfY/tZ0lbHxxYY34hdCCxquQx1tXZZjLQrnv1j/0OoYOkHf26o2TS9gbYvF7EkZAmVYXQa7qlAbbOYFJq1728kdBMYFRmmoYwlhh1zRqwdYbErtl1L4Q69bFaqaMMSadLWibp1kLaCZKWDLTJm6Tjcm/rnZL2KaQPuye2tpKJ7ZWSGrvujQNOr2PXvRA6WQ1rwJ4BfAc4q1/6N2x/tZggaRvSj/xrgM2BKyVtlV8edk9srW0mti8FLq0zjxA6mal2BKztayVNLnn6gcB5tpcD90paxPObwC+yfQ+ApEZPbNNg0h0tPyF0sFFaUPpoSbfkatBGOW2gHtctmqQ3FcEkhDayxSqvVuoAJkiaWzjKLnZ9MvBK0ubrS4Gv1fFZ2t41HEKvG8Y4k4eH2rh8ILYfbDyWdApwcX7arMd1yJ7Y/qJkEkIbpcWR6h0BK2mzwtO3A42enlnAwZLGS5oCTAVuYoQ9sVEyCaGtql1QWtK5wG6kKtFi4HhgN0nTSbHrPuDDALZvk3Q+qWF1JXCU7b58nWH3xEYwCaGNDJV2Dds+ZIDk05qcfxJw0gDpw+6JjWASQht10wjYCCYd7tUnLKo9j77ac+htsaB0CKFlaT2TKJmEECoQ1ZwQQstSm0lUc0IIFYiNy0MILTNi5aqxv1h0GRFMQmizTljftYwIJiG0UfTmhBAq0y0NsLV9ioGWjwshvFBjBGyZY6yrMySeAexb4/VD6Aqxb84Qhrl8XAg9KS3bOPYDRRnRZhJCOzm6hisTm3CFXtZYHKkbtD2YxCZcoddFNSeE0LJuajOps2v4XOB6YGtJiyUdUVdeIXSybukarrM3Z6Dl40IIBbHSWgihGoaVXTICNoJJCG0UbSYhhMpU2WYy0DQWSf8r6Y68PehFkjbM6ZMlPSNpQT6+X3jP6yT9QdIiSd+WNOQNRDAJoY1qmJtzBi+exjIbmGZ7W+CPwHGF1+62PT0fHymknwz8G2ljrqkDXPNFIpiE0Ga2Sh3lruVrgUf7pV1he2V+egNpu89B5R0A17d9g20DZwEHDZV3BJMQ2myUJ/r9K/DLwvMpkn4v6deSdslpWwCLC+cszmlNRQNsCG1kD6sBdoKkuYXnM/MI8lIk/TdpG9BzctJSYJLtRyS9DviZpNeUvV5/EUw63MIvvaL2PLY68pHa8+hdom9V6QrCw7ZnjCgX6XDgAGCPXHXB9nJgeX48T9LdwFbAEl5YFZqY05qKak4IbVZlm8lAJO0LfAp4m+2nC+mbSBqXH7+C1NB6j+2lwOOSdsq9OB8Afj5UPlEyCaGNqh5nkqex7EaqEi0Gjif13owHZuce3htyz82uwImSVgCrgI/YbjTefpTUM7Q2qY2l2M4yoAgmIbSTU7tJZZcbeBrLaYOceyFw4SCvzQWmDSfvCCYhtFmsZxJCaJmhpfaQsSSCSQhtFbOGQwgVWbUqgkkIoUV2VHNCCBXplmpOncs2binpakm3S7pN0sfqyiuETmaXO8a6OksmK4FP2J4vaT1gnqTZtm+vMc8QOk5Uc4aQh+QuzY+fkLSQNPMwgkkImWltqPxYMiptJnmb0O2AG0cjvxA6SQfUYEqpPZhIWpc0ZPfjth8f4PXY0S/0LoO7vWtY0vbN3mh7/lAXl7QGKZCcY/ung1wndvQLPa0Xqjlfa/Kagd2bXThPXT4NWGj76yO4txB6Qif01JQxaDCx/ZYWr70zcCjwB0kLctpnbF/a4nVD6Bo9NTdH0jrAsaTl3Y6UNBXY2vbFzd5n+zrokumQIdTFQJcEkzKD1n4APAu8MT9fAnyxtjsKocd0y6C1MsHklba/AqwAyMu+dUcoDWEscMljjCvTNfyspLXJH0fSK8mL0IYQWqXu7xouOB64DNhS0jmkhtXD67ypEHpGL80atj1b0nxgJ1L15mO2H679zkLoFR1QhSmj7AjYNwNvIn3sNYCLarujEHpOj5RMJH0PeBVwbk76sKQ9bR9V652F0Ct6qGSyO/CPjV3AJJ0J3FbrXYXS7j3glNrz2IfptefR0yoMJpJOJ+3ct8z2tJy2MfBjYDJwH/Bu24/lUerfAvYHngYOb0yTkXQY8Nl82S/aPnOovMt0DS8CJhWeb5nTQgityhP9yhwlnQHs2y/t08BVtqcCV+XnAPuRdvGbSppsezI8F3yOB3YEdgCOl7TRUBkPGkwk/ULSLGA9YKGkayRdDSzMaSGEKlQ4zsT2tcCj/ZIPBBolizOBgwrpZzm5AdhQ0mbAPsBs24/afgyYzYsD1Is0q+Z8tdzthxBaUr5reIKkuYXnM/Os+6FsmhcrA/gLsGl+vAVwf+G8xTltsPSmmk30+3WJmwwhtEjl20wetj2jlbxsWxpGjsMwZJtJ3gl9jqQnJT0rqU/SixY5CiGMQNkqTmtf/wdz9YX857KcvoTUBtowMacNlt5UmQbY7wCHAHeRdkT/EPDdEu8LIQxJqZpT5hi5WcBh+fFhwM8L6R9QshPwt1wduhzYW9JGueF175zWVKmtLmwvAsbZ7rP9A0o0xoQQSqqwZCLpXOB6YGtJiyUdAfwPsJeku4A983OAS4F7SL2zpwAfBbD9KPAFYE4+TsxpTZUZZ/K0pDWBBZK+Qlpxvrb9dkLoOauqu5TtQwZ5aY8BzjUw4OBT26cDpw8n7zJB4dB83tHAU6S61DuGepOktSTdJOnmvAnX54dzYyH0hMbiSPVWc0ZFmYl+f8oP/w58HkDSj4H3DPHW5cDutp/MC0tfJ+mXuT87hJDV07cy+ka61cUbhjohF6GezE/XyEeX/LWFUKEu+VbU2vYhaVxeTHoZaURdbMIVQpcayb45IpUyhmS7D5guaUPgIknTbN/aL5/YhCv0tF6o5jTbN+eO4WRi+695Xs++wK39XotNuEJv64DG1TJq2zdH0ibAihxI1gb2Ar7cyjVD6Dqm0q7hdqpzr+HNgDMljSO1zZw/1F47IfSiXqjmtMT2LcB2dV0/hK4RwSSEUIkuCSZlZg1L0vslfS4/nyRph/pvLYTuJ5c/xroy40y+Rxqk1hjz/wQxaziE6vTKcHpgR9vbS/o9QF6Ids2a7yuE3tEBpY4yygSTFblHprE6/SZ0TWdWCO2nLvk2lanmfJu06dbLJJ0EXAd8qda7CqFXdFGbSZlZw+dImkdaD0HAQbYX1n5nIfSKDggUZZTZ0W8SaYOeXxTTbP+5zhsL5ex260FDn9Si8dxXex49rVeCCXAJ6eMKWAuYAtwJvKbG+wqhZ3RCFaaMMtWcfyo+z7OJP1rbHYUQOtKwR8Dani9pxzpuJoSe1CslE0nHFp6uBmwPPFDbHYXQS9xbXcPrFY7xpDaUA+u8qRB6SkVbXUjaWtKCwvG4pI9LOkHSkkL6/oX3HCdpkaQ7Je3TysdoWjLJg9XWs/3JVjIJIQxMVNcAa/tOYDo8991dQhoj9kHgG7ZfsH+4pG2Ag0mdKZsDV0raKq+QOGyDlkwkrZ4vuvNILhxCKKme7UH3AO4u7C4xkAOB82wvt30vaTOuEU/ibVbNuSn/uUDSLEmHSnpH4xhphiGEgvpGwB4MnFt4frSkWySdnrf8BNgCuL9wzuKcNiJl2kzWAh4BdgcOAP45/xlCqEL5kskESXMLx5EDXS5PxH0b8JOcdDLwSlIVaCnN13cesWZtJi/LPTm38vygtYbScTLX3eYCS2xHEAqhn2H05jxse0aJ8/YD5tt+EKDxJ4CkU4DG8qlLSDt0NkzMaSPSrGQyDlg3H+sVHjeOsj4GxFyeEAZTfZvJIRSqOJI2K7z2dp7fIWIWcLCk8ZKmAFN5vnlj2JqVTJbaPnGkFwaQNBF4K3AScOwQp4fQe0bWuDooSS8h7QTx4ULyVyRNzznd13jN9m2SzgduB1YCR420JweaB5Mqlnb6JvApUskmhDCAKufm2H4KeGm/tEObnH8S6ce+Zc2qOXu0cmFJBwDLbM8b4rwjGw1KK1jeSpYhdKZ6uoZH3aDBxPajLV57Z+Btku4DzgN2l3T2APnMtD3D9ow1GN9iliF0nm5ZHKm2jcttH2d7ou3JpD7vX9l+f135hdCxuqRkEvvmhNBGnVLqKGNUgonta4BrRiOvEDpOBJMQQhWiZBJCqEYEkxBCJSKYhBBaFg2wIYTKRDAJIVShW9aAjWASQptFNSeMCQ/+dvPa85gUO/rVp0NGt5YRwSSEdotgEkJoVZWr07dbBJMQ2i2CSQihCnJ3RJMIJiG0UxdtDxrBJIR2646CSQSTENotGmBDCNWIYDK0vP7rE0AfsLLkBkIh9I6KJ/oN9J2TtDHwY2AyaauLd9t+TJKAbwH7A08Dh9ueP9K8a1sDtuAttqdHIAlhENWvAdv/O/dp4CrbU4Gr8nNIO/9NzceRpG1ER2w0gkkIYRCNQWs1r05/IHBmfnwmcFAh/SwnNwAb9tv9b1jqDiYGrpA0b7BNlkPodVrlUkdJA33nNrW9ND/+C7BpfrwFcH/hvYtz2ojU3QD7JttLJL0MmC3pDtvXFk/IH/hIgLVYp+bbCWGMGV4VZoKkuYXnM23P7HfOi75zL8jOtlRP/1GtwcT2kvznMkkXATsA1/Y7ZyYwE2B9bdwl7dohlDeMQWsPD9X2OMh37kFJm9lemqsxy/LpS4AtC2+fmNNGpLZqjqSXSFqv8RjYm+d3Xw8hNFTUANvkOzcLOCyfdhjw8/x4FvABJTsBfytUh4atzpLJpsBFqfeJ1YEf2b6sxvxC6EgVVjoG/M5JmgOcL+kI4E/Au/P5l5K6hReRuoY/2ErmtQUT2/cAr63r+iF0BQMVTfQb7Dtn+xFgjwHSDRxVSebECNgQ2i4m+oUQWhaLI4UQqmFXVs1ptwgmIbRZlExCCNWIYBJCqEKUTEIIrTNQft7NmBbBpMOt+/qH230LoUXRNRxCqEb05oQQqhBtJiGE1sVewyGEKqQRsN0RTSKYhNBu0QAbQqhClExCCK2zY5xJCKEa0ZsTQqhGl1Rzat3qQtKGki6QdIekhZLeUGd+IXQcpxGwZY6xru6SybeAy2y/U9KaEHtZhPAiXVIyqS2YSNoA2BU4HMD2s8CzdeUXQsfqjlhSazVnCvAQ8ANJv5d0al5+P4RQILvUMdbVGUxWB7YHTra9HfAUz2+Y/BxJR0qaK2nuCpbXeDshjEEG+lzuGOPqDCaLgcW2b8zPLyAFlxewPdP2DNsz1mB8jbcTwtgjypVKypRMJG0p6WpJt0u6TdLHcvoJkpZIWpCP/QvvOU7SIkl3Stqnlc9S5745f5F0v6Stbd9J2rfj9rryC6FjVVeFWQl8wvb8vLPfPEmz82vfsP3V4smStgEOBl4DbA5cKWkr230jybzu3pxjgHNyT849tLhjWAhdqbpNuJYCS/PjJyQtBLZo8pYDgfNsLwfulbSItDfx9SPJv9ZxJrYX5CrMtrYPsv1YnfmF0HFMmuhX5oAJjfbFfBw52GUlTQa2AxrNDEdLukXS6ZI2ymlbAPcX3raY5sGnqVqDSQhhaMNoM3m40b6Yj5kDXk9aF7gQ+Ljtx4GTgVcC00kll6/V8TliOH0I7VZht6+kNUiB5BzbP02X94OF108BLs5PlwBbFt4+MaeNSJRMQmgnG1atKncMQZKA04CFtr9eSN+scNrbgVvz41nAwZLGS5oCTAVuGulHiZJJCO1W3bybnYFDgT9IWpDTPgMcImk6qYXmPuDDALZvk3Q+qZd1JXDUSHtyIIJJCG1X1ehW29eRVoLs79Im7zkJOKmK/COYhNBuHTBUvowIJiG0U+zoV48neOzhK33Bn4bxlgnAaGxpNxr5jCyPt45SPmMvj9HKZyR5vLz8qY6SSR1sbzKc8yXNtT2jrvsZzXzis4zNfEbls0QwCSG0zEBfByyjVkIEkxDayuAIJmPBgMOJOzSf+CxjM5/68+iSak5Hj4AdbG7CWMhHUl9eO+JWST+R1HT922Z5SDpD0jvz41Pz1PHBzt1N0huHm4+k+yRNKJs+yDUOl/Sd4fx9Def6/Y3Gv3/teTR6c8ocY1xHB5Mx7hnb021PI619+5Hii5JGVCq0/SHbzdaF2Q0YNJiEMcgud4xxEUxGx2+AV+VSw28kzQJulzRO0v9KmpOnh38Y0hwLSd/Jq19dCbyscSFJ10iakR/vK2m+pJslXZWnnX8E+M9cKtpF0iaSLsx5zJG0c37vSyVdkVfkOpWBR04OSNIOkq7Pa/v+TtLWhZe3zPd4l6TjC+95v6Sb8n39P0njRvy32W26JJh0epvJmJdLIPsBl+Wk7YFptu/N61H8zfbrJY0HfivpCtI6FFsD2wCbkuZOnN7vupsApwC75mttbPtRSd8HnmysqiXpR6RVtq6TNAm4HPhH4HjgOtsnSnorcMQwPtYdwC62V0raE/gS8C/5tR2AacDTwBxJl5DW/30PsLPtFZK+B7wPOGsYeXYnG/pGPB1mTIlgUp+1C5OtfkOazflG4Cbb9+b0vYFtG+0hwAakmZu7AufmSVcPSPrVANffCbi2cS3bjw5yH3sC26QJpQCsn9e72BV4R37vJZKGs3DVBsCZkqaSav1rFF6bbfsRAEk/Bd5EmkT2OlJwAVgbWDaM/LpbB5Q6yohgUp9nbE8vJuQv0lPFJOAY25f3O29/qrMasJPtvw9wLyP1BeBq22/PVatrCq/1/2aY9DnPtH1cK5l2rS4JJtFm0l6XA/+eF7RB0lZKewtdC7wnt6lsBrxlgPfeAOya16FA0sY5/QlgvcJ5V5DW4iWf1whw1wLvzWn7ARtR3gY8v4jO4f1e20vSxpLWBg4CfgtcBbxT0ssa9yppGEPOu1nJnpwO6M2Jkkl7nQpMBubnhW0eIn0BLwJ2J7WV/JkBFvi1/VBuc/mppNVI1Ya9gF8AF0g6kBRE/gP4rqRbSP/e15IaaT8PnCvpNuB3OZ/B3CI9t9vt+cBXSNWczwKX9Dv3JtJKXxOBs23PBcjnXpHvdQVwFDCceVjdyeAuGbQmd0kRK4ROtMHqm/gN6x9U6tzLHzt13mjMeRqpKJmE0G5d8oMewSSEdoqu4RBCVVxisehOEMEkhLbqjNGtZUQwCaGdumjZxhhnEkK7eVW5o4Q8X+tOSYskfbrmO3+BKJmE0EYGXFHJJE+e/C5pvNFi0vSFWUPMMq9MlExCaCe7ypLJDsAi2/fYfhY4Dziw1vsviJJJCG3m6rqGtwDuLzxfDOxY1cWHEsEkhDZ6gscuv9IXlF1pbi1JcwvPZ47WaoNlRDAJoY1s71vh5ZYAWxaeT+T5CZm1izaTELrHHGCqpCmS1gQOBmaNVuZRMgmhS+SV744mLW0xDjjd9m2jlX/MGg4hVCKqOSGESkQwCSFUIoJJCKESEUxCCJWIYBJCqEQEkxBCJSKYhBAqEcEkhFCJ/w9jHmW0vzbRLgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 288x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TppZq1uaHUe"
      },
      "source": [
        "##References\n",
        "1) S. (2019, November 27). Facial Expression Detection (CNN). Kaggle. https://www.kaggle.com/shawon10/facial-expression-detection-cnn\n",
        "\n",
        "2) J. (2019a, January 3). Face expression recognition with Deep Learning. Kaggle. https://www.kaggle.com/jonathanoheix face-expression-recognition-with-deep-learning\n",
        "\n",
        "3) G. (2020, April 18). Facial Emotion Recognition. Kaggle. https://www.kaggle.com/gauravsharma99/facial-emotion-recognition\n",
        "\n",
        "4) https://gist.github.com/Nabeel110/01210a28cbd8b53c13b42330abc253ad"
      ]
    }
  ]
}